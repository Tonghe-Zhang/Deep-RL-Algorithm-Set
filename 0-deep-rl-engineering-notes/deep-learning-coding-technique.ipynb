{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch.nn.Linear  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the linear neuron net:\n",
    "input dimension\n",
    "output dimension\n",
    "the linear network has an attributte called .weight and .bias, both of them are tensors. \n",
    ".weight is of shape $\\R^{d_{out}\\times d_{in}}$\n",
    ".bias is of shape $\\R^{d_{out}}$\n",
    "During forward propagation, the linear net does thisï¼š\n",
    "\n",
    "$y= x A^{\\top} + b$\n",
    "\n",
    "where $A$ is the weight and b is the bias.\n",
    "\n",
    "Notice that linear supports batch computation, and it only works on the last dimension of $x$. \n",
    "$y: (*, \\R^{d_{out}})$\n",
    "$x: (*, \\R^{d_{in}})$\n",
    "\n",
    "\\* indicates arbitrary dimension tuple.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n",
      "torch.Size([5])\n",
      "torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "in_dim=10\n",
    "out_dim=5\n",
    "fc=nn.Linear(in_dim,out_dim)\n",
    "batch_input_data=torch.randn(3,in_dim)\n",
    "batch_output_data=fc(batch_input_data)\n",
    "print(fc.weight.shape)\n",
    "print(fc.bias.shape)\n",
    "print(batch_output_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hydra\n",
    "How to use hydra to set configurations for the main function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "@hydra.main(config_path=\"config.yaml\")\n",
    "def my_app(cfg: DictConfig) -> None:\n",
    "    # Your Hydra-enabled application code here\n",
    "    print(cfg.pretty())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    my_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example:\n",
    "@hydra.main decorates the entry point function my_app. It tells Hydra that it is the main function to be executed.\n",
    "config_path=\"config.yaml\" specifies the path to the configuration file that Hydra should use.\n",
    "cfg: DictConfig is the configuration object that will be passed to your main function.\n",
    "You can then run your Hydra-enabled script, and Hydra will handle the configuration loading and setup based on the config.yaml file you provide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use hydra to instantiate some kind of function from a function class, as specified by some config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra.utils import instantiate\n",
    "# Define your configuration as a dictionary\n",
    "config = {\n",
    "    \"_target_\": \"module_name.ClassName\",  # Specify the target module and class to instantiate\n",
    "    \"param1\": value1,\n",
    "    \"param2\": value2\n",
    "}\n",
    "# Instantiate an object using the configuration\n",
    "obj = instantiate(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_target_: Specifies the target module and class to instantiate. This key is mandatory.\n",
    "\n",
    "Other keys such as \"param1\", \"param2\", etc., are used to provide values for the parameters of the class being instantiated.\n",
    "\n",
    "When configuring the _target_ key, you should provide the full import path of the module and class you want to instantiate.\n",
    "\n",
    "For example: \"module_name.ClassName\"indicating the module named module_name and the class within it called ClassName."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example you can use activation dictionary to specify the activation function used in this Python application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation:\n",
    "    target_: torch.nn.ELU\n",
    "    # you can define parameters of the __init__ function for the object here\n",
    "    inplace: False  # use inplace activation to save memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assert some boolean expression ,  'logging error message string'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "var must be a negative integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m*\u001b[39mvar)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(func(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mfunc\u001b[1;34m(var)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(var:\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m\u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(var)\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mint\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m var \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvar must be a negative integer\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m*\u001b[39mvar)\n",
      "\u001b[1;31mAssertionError\u001b[0m: var must be a negative integer"
     ]
    }
   ],
   "source": [
    "def func(var:int)->float:\n",
    "    assert greedy(var)==int and var < 0, 'var must be a negative integer'\n",
    "    import numpy as np\n",
    "    return np.sqrt(-1*var)\n",
    "\n",
    "print(func(-1))\n",
    "\n",
    "print(func(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross referencing in .yaml files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "train:\n",
    "  nstep: ${buffer.nstep}\n",
    "agent:\n",
    "  gamma: 0.99\n",
    "  nstep: ${buffer.nstep}\n",
    "\n",
    "buffer:\n",
    "  nstep: 1\n",
    "  gamma: ${agent.gamma}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective-oriented Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size, hidden_size, activation):\n",
    "        super(QNetwork, self).__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you inherit some class from a super class e.g. the nn.Module in this example, then when you define the __init__ method of the subclass, the first thing to do\n",
    "is the initialize the super class's constructor first. Like you write super(SubClassName, self).__init__(SuperClassInitParameters)\n",
    "to pass the subclass's name to superclass' constructor is for readabilty. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use dir() to check the attributes/methods/structure of an unfamiliar module/instance/library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how dir() works and what it returns:\n",
    "\n",
    "Syntax: The syntax of dir() is dir(object). When you pass an object to dir(), it inspects the object and returns a sorted list of names comprising its attributes.\n",
    "\n",
    "Output:\n",
    "\n",
    "For a module: dir(module) returns a list of all the names defined in the module's namespace.\n",
    "\n",
    "For a class or instance: dir(class_or_instance) returns a list of attributes and methods that the class or instance has access to.\n",
    "\n",
    "If you call dir() without an object (i.e., dir()), it returns a sorted list of the names in the current local scope.\n",
    "\n",
    "Using dir() is a handy way to explore an object's attributes and methods, especially when working with unfamiliar libraries or objects. It helps you discover what functionality is available and can be particularly useful for interactive exploration and debugging in Python scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random generator in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# random generator abbreviated as 'rng'.\n",
    "rng=np.random.default_rng\n",
    "\n",
    "# Generate a random integer between 0 and 100\n",
    "random_int = rng.integers(0, 101)\n",
    "\n",
    "# Generate an array of random numbers from a normal distribution\n",
    "random_array = rng.normal(loc=0, scale=1, size=10)\n",
    "\n",
    "# check all the methods in rng.\n",
    "print(dir(rng))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use dataloader\n",
    "\n",
    "DataLoader receives the dataset, split it into multipl batches with given sizes, and then returns an iterator. If you iter through the returned Iterator, you get each of the batched samples. \n",
    "\n",
    "* .to(device, non_blocking=True)\n",
    "\n",
    "After you load the data in, use .to(device, non_blocking=True)  to \n",
    "\n",
    "1. move data to cpu/gpu specified by 'device'\n",
    "\n",
    "2. use asynchronous loading to accelerating data transfer. non_blocking typically means we do not block other procedures of the cpu during data loading process.\n",
    "\n",
    "* .pin_memory()\n",
    "and then you can use .pin_memory() to further accelerate data usage on the GPU:\n",
    "\n",
    "When you call .pin_memory() on a tensor or a batch of tensors within a PyTorch DataLoader, it ensures that the data is copied into pinned memory, which can be transferred to the GPU more efficiently. \n",
    "\n",
    "* .is_contiguous()  and .contiguous()\n",
    "If a Tensor is created by slicing some rows and/or columns from another Tensor, then its memory is usually not contiguously allocated, which may slow down data processing.\n",
    "So after loading data or receiving data as an input parameter, you can first check whether it is contiguously allocated, then if it is not, make it so.\n",
    "\n",
    "here is_contiguous() returns a Boolean number indicating whether data is currently contiguous. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create a PyTorch DataLoader\n",
    "dataset = ...\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "device='cuda'\n",
    "# DataLoader receives the dataset, split it into multipl batches with given sizes, and then\n",
    "# returns an iterator. If you iter through the returned Iterator, you get each of the batched samples. \n",
    "\n",
    "# Iterate through the DataLoader.\n",
    "for data in dataloader:\n",
    "    input_data, target = data\n",
    "    input_data = input_data.to(device, non_blocking=True).pin_memory()\n",
    "    if not input_data.is_contiguous():\n",
    "        input_data=input_data.contiguous()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use \\__repr\\__() to specify the representation string of a class\n",
    "You do this for readability. You can specify the name of your class when you print an object instantiated from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name_of_MyClass(x=3, y=2)\n"
     ]
    }
   ],
   "source": [
    "class MyClass:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Name_of_MyClass(x={self.x}, y={self.y})\"\n",
    "\n",
    "obj=MyClass(3,2)\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Copy \n",
    "Deep copy:    copy.deepcopy() is  method that makes a deep copy of the object. \n",
    "Changing its source will not affect the copy.\n",
    "v.s. \n",
    "shallow copy: only copies a reference, so changing the source will also affect the copied obj."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# Original list\n",
    "original_list = [1, 2, [3, 4], 5]\n",
    "\n",
    "# Deep copy of the original list\n",
    "copied_list = copy.deepcopy(original_list)\n",
    "\n",
    "# Modify the nested list within the copied list\n",
    "copied_list[2][0] = \"Changed\"\n",
    "\n",
    "# Output the original and copied list\n",
    "print(\"Original List:\", original_list)\n",
    "print(\"Copied List:\", copied_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @torch.no_grad and .detach()\n",
    "\n",
    "* @torch.no_grad() is use as a decorator to mark a function as not requiring gradient computation.\n",
    "\n",
    "**When do we use it:**\n",
    "Inference(forward propagation)\n",
    "Evaluation(computint validation metrics, outputing logs)\n",
    "\n",
    "**How to use it:**\n",
    "we write it on top of a function definition, so that all the tensors within the function will not require gradient computation, i.e. their attribute .requires_grad will be set to False.\n",
    "\n",
    "**Why do we use it:**\n",
    "save memory and accelerate computation.\n",
    "\n",
    "* .detach() is a method of the tensor that creates a new tensor that shares the same storage with the original tensor, but does not require gradient computation.\n",
    "\n",
    "**When do we use it:**\n",
    "like when you only want the values of a tensor, like some specific regularization terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to use zip():\n",
    "It chooses items from multiple iterables of the same length and pack them into tuples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'a', -3) <class 'tuple'>\n",
      "(2, 'b', -5) <class 'tuple'>\n",
      "(3, 'c', -7) <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "for i in zip([1,2,3],['a','b','c'],(-3,-5,-7)):\n",
    "    print(i, type(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
