[toc]



# DRL project schedule



## Week 10 –> Week 11

> 1. Read codes: baselines, and trim/augment paper+ codes
>
> 2. Read papers about exploration & data augmentation
>
>   **curiosity ?**    **modify reward ?** 
>
> Relationship between exploration and diffusion model’s generation can we discover generalization in distributions?    $\text{[literature review search deeper ! !]}$  will generated data help generalize and exploration or exacerbates overfitting? how and why? 
>
> 3. Try out offline classical baselines, if someone works, share codes. 	
>
> ​	*<u>**Baseline:**</u>*   *<u>**3 envs**</u>*     *<u>**Q-DT +env**</u>*

## Week 12 -> Week 14

**need another meeting.**

> Trim/AUg
>
> ​		 **data-clean/select**
>
>   	       **curiosity ?** 
>
> ​		 **modify reward ?**
>
> ​		 **diffusion generation**
>
> Re-implement modules, parallel. 
>
> * Tonghe:
>
> * Wei:
> * Yucheng:
> * Yulong:

## Week 14-15  Try out new ideas (if we have time)

> 1. **Relationship between exploration and diffusion model’s generation** 
>
> **can we discover generalization in distributions?**    $\text{[literature must search]}$  
>
> 2. **Reward regularization to generate higher rewards**
>
> 3. **Dynamic model is it necessary and how to improve** 
>
> 4. Experiment: bonus penalization? (still generalize)
> 5. New data augmentation ideas

